import google.generativeai as genai
import os
import logging
from typing import Optional
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

logger = logging.getLogger(__name__)

# Configure Gemini API
def configure_gemini():
    """Configure Gemini API with proper error handling."""
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        logger.warning("GEMINI_API_KEY not found in environment variables")
        return False
    
    # Check if it's a placeholder
    if api_key == "your_gemini_api_key_here":
        logger.warning("Please set a real GEMINI_API_KEY in your .env file")
        return False
    
    try:
        genai.configure(api_key=api_key)
        logger.info("Gemini API configured successfully")
        return True
    except Exception as e:
        logger.error(f"Failed to configure Gemini: {e}")
        return False

# Initialize model
model = None
if configure_gemini():
    # Try different model names
    model_names = ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-pro"]
    
    for model_name in model_names:
        try:
            model = genai.GenerativeModel(model_name)
            logger.info(f"Gemini model initialized successfully with: {model_name}")
            break
        except Exception as e:
            logger.warning(f"Failed to initialize model {model_name}: {e}")
            continue
    
    if not model:
        logger.error("Failed to initialize any Gemini model")

def query_interaction_gemini(drug: str, food: str) -> str:
    """
    Query Gemini AI for drug-food interaction information.
    
    Args:
        drug (str): Standardized drug name
        food (str): Food item to check for interactions
    
    Returns:
        str: AI-generated interaction analysis with disclaimer
    """
    if not model:
        return "⚠️ **AI Service Unavailable**\n\nGemini AI is not properly configured. Please check your API key in the .env file and try again."
    
    try:
        # Enhanced prompt for concise, structured responses
        prompt = f"""
        Analyze the interaction between {drug} and {food}. Provide a structured response in this exact format:

        **RISK LEVEL**: [High/Moderate/Low/None]

        **INTERACTION**: [Yes/No] - Brief explanation

        **RECOMMENDATION**: [Avoid/Limit/Monitor/Safe] - What to do

        **REASON**: [1-2 sentences explaining why]

        Keep it concise and actionable. Focus on practical advice for the patient.
        """
        
        logger.info(f"Querying Gemini for {drug} + {food}")
        response = model.generate_content(prompt)
        
        if response and response.text:
            # Add disclaimer to AI-generated content
            ai_response = response.text.strip()
            disclaimer = "\n\n---\n⚠️ **AI-Generated Content Disclaimer**\n\nThis information was generated by artificial intelligence and should not be considered as medical advice. Always consult with a healthcare provider or pharmacist for personalized medical guidance."
            
            return ai_response + disclaimer
        else:
            return "⚠️ **No Response from AI**\n\nUnable to generate a response. Please consult a healthcare provider."
            
    except Exception as e:
        logger.error(f"Error querying Gemini: {e}")
        return f"⚠️ **AI Service Error**\n\nAn error occurred while analyzing the interaction: {str(e)}\n\nPlease consult a healthcare provider for accurate information."

def get_interaction_risk_level(drug: str, food: str) -> Optional[str]:
    """
    Get a quick risk assessment for the drug-food combination.
    
    Returns:
        str: Risk level (High/Moderate/Low/None) or None if unavailable
    """
    if not model:
        return None
    
    try:
        prompt = f"""
        For {drug} and {food}, provide ONLY a single word risk assessment:
        - "High" if there are significant known interactions
        - "Moderate" if there are minor or theoretical interactions  
        - "Low" if interactions are unlikely but possible
        - "None" if no known interactions exist
        
        Respond with just the risk level word.
        """
        
        response = model.generate_content(prompt)
        if response and response.text:
            risk_level = response.text.strip().lower()
            if risk_level in ['high', 'moderate', 'low', 'none']:
                return risk_level.title()
        
        return None
        
    except Exception as e:
        logger.error(f"Error getting risk level: {e}")
        return None